{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#Use this line to set the number of  CPU used for execution of the program (if it's not working, use the commented line:\n",
    "#see https://stackoverflow.com/questions/17053671/python-how-do-you-stop-numpy-from-multithreading/21673595 for more information)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '5' \n",
    "os.environ['MKL_NUM_THREADS'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Low rank VAR(1) Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this notebook is to implement and to test the low_rank VAR(1) algorithm. In order to do so, we will:\n",
    "- generate data according to a low-rank high dimensionnal VAR(1) process\n",
    "- implement the estimation of the low rank VAR(1) models\n",
    "- compare this model with a standard VAR(1) among differents  features\n",
    "\n",
    "\n",
    "We want to simulate an VAR(1) processus generated by a matrix A of rank r. We consider the time series $(X_t) \\in \\mathbb{R}^M$ of length generated by \n",
    "\n",
    "$$ X_{t+1} = A X_t + \\epsilon_t   $$\n",
    "    \n",
    "where $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma^{2})\\$ \n",
    "\n",
    "\n",
    "## I Generation\n",
    "\n",
    "\n",
    "In order to generate A, we use the following procedure:\n",
    "\n",
    "- We uniformly generate U and V matrices of respective shape $M\\times r$ and $r \\times M$. \n",
    "- We transform U and V using Gram-Schmdit otrhonomalization\n",
    "- We generate $\\lambda_1,\\dots\\lambda_r$ r singular values according to a $\\mathcal{\\beta}(a,1)$ distribution\n",
    "- We take $A = U diag(\\lambda_1, \\dots, \\lambda_r) V^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_unit_matrix(M,P):\n",
    "    \"\"\"Generation of a MxP unit matrices using Gram Schmidt Orthonormalization\"\"\"\n",
    "    list_col = [ np.random.uniform(low = - 1, size = M) for i in range(P)]\n",
    "    \n",
    "    new_list_col = list()\n",
    "    for  col in list_col:\n",
    "        new_col = col\n",
    "        for old_col in new_list_col:\n",
    "            new_col -= old_col.dot(col) * old_col\n",
    "        new_col = new_col/np.linalg.norm(new_col)\n",
    "        new_list_col.append(new_col)\n",
    "    \n",
    "    list_col = [col.reshape(M,1) for col in new_list_col]\n",
    "    \n",
    "    return np.concatenate(list_col , axis = 1)\n",
    "\n",
    "\n",
    "def generate_matrix(M, r, a) : \n",
    "    U = random_unit_matrix(M,r)\n",
    "    V = random_unit_matrix(M,r).transpose()\n",
    "    diag = np.diag(np.random.beta(a,1, size =r))\n",
    "    A =  U.dot(diag.dot(V))\n",
    "    return A\n",
    "\n",
    "def tronc_gaussian(sigma, limit = 1):\n",
    "    \"\"\"Truncated centred gaussian distribution with deviation sigma\"\"\"\n",
    "    ret = np.random.normal(scale = sigma)\n",
    "    if abs(ret) > limit:\n",
    "        return tronc_gaussian(sigma, limit=limit)\n",
    "    return ret\n",
    "\n",
    "def vect_tronc_gaussian(n,m, sigma = 1, limit = 1):\n",
    "    A = np.array([tronc_gaussian(sigma, limit=limit) for i in range(n*m)])\n",
    "    return A.reshape((n,m))\n",
    "\n",
    "def generate_series(A,n,sigma= 1, limit_gaussian = 10 ):\n",
    "    M = A.shape[0]\n",
    "    cur =  vect_tronc_gaussian(M,1,sigma= sigma, limit=limit_gaussian)\n",
    "    list_vect = [cur]\n",
    "    for i in range(n-1):\n",
    "        cur = A.dot(cur) + vect_tronc_gaussian(M,1,sigma=sigma, limit=limit_gaussian)\n",
    "        list_vect.append(cur)\n",
    "    return np.concatenate(list_vect, axis = 1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  II Three estimators\n",
    "\n",
    "### II.A Benchmark : Full Rank Estimator\n",
    "\n",
    "To compare the performance of our model, we use the standard VAR(1) estimator $\\widehat{A}_{std}$ defined as :\n",
    "\n",
    "$$ \\widehat{A}_{std}  =\\underset{A \\in \\mathcal{M}_{M \\times M }(\\mathbb{R})}{argmin} \\sum_{i=0}^n \\|X_{i+1} - A X_i \\|_2^2 $$ \n",
    "\n",
    "If we set :\n",
    "\n",
    "$$ Y = \\left(X_1| X_2 | \\dots | X_n \\right)$$\n",
    "$$ X = \\left(X_0|X_1 | \\dots | X_{n-1} \\right)$$\n",
    "\n",
    "We have then \n",
    "\n",
    "$$  \\widehat{A}_{std} = \\underset{A \\in \\mathcal{M}_{M \\times M }(\\mathbb{R})}{argmin} \\|Y- AX \\|_F^2 $$\n",
    "\n",
    "where $\\|\\|_F$ is the Frobenius norm. Therefore, we can have an exact expression for $\\widehat{A}_{std}$:\n",
    "$$\\widehat{A}_{std} = (X X^T)^{-1} X^T Y$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def empirical_risk(estim,series ):\n",
    "    \"\"\"Empirical Squared L2 risk for a matrix estim\"\"\"\n",
    "    n = series.shape[1]-1 \n",
    "    return( 1/n * sum([np.linalg.norm(series[:,i+1] - estim @ series[:,i])**2  for i in range(n)]) ) \n",
    "\n",
    "def std_estimator(series):\n",
    "    \"\"\" Full rank estimator\"\"\"\n",
    "    Y = series[:,1:]\n",
    "    X = series[:,:-1]\n",
    "    return  (Y @ X.transpose()) @  np.linalg.inv(X@ X.transpose() ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.B Low Rank Estimator\n",
    "\n",
    "In this setting, we perform the minimization describe in the paper \n",
    "\n",
    "$$ \\widehat{U}_{low rank}, \\widehat{V}_{low rank}  =\\underset{U,V \\in \\mathcal{M}_{M \\times r }(\\mathbb{R})}{argmin} \\sum_{i=0}^n \\|X_{i+1} - U V^T X_i \\|_2^2 $$ \n",
    "\n",
    "And we have then $\\widehat{A}_{low rank} = \\widehat{U}_{low rank} \\widehat{V}_{low rank} $\n",
    "\n",
    "To perform this minimization, we alternate minimisation on $U$ then $V$. There are also exact expression for this form. When we suppose that we know the underlying rank of the simulation, this estimator is called an 'oracle' estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_U(V,X,Y):\n",
    "    VX =  V @ X\n",
    "    return (Y @ VX.transpose()) @  np.linalg.inv(VX@ VX.transpose() ) \n",
    "    \n",
    "def min_V(U,X,Y):\n",
    "    tUYtX = U.transpose() @ Y @ X.transpose()\n",
    "    return np.linalg.inv(U.transpose()@ U ) @ tUYtX  @  np.linalg.inv(X@ X.transpose() ) \n",
    "\n",
    "def low_rank_estimator(series, r = 10 ,  n_iter = 20, verbose = False ):\n",
    "    \"\"\"Low rank estimator with alternate minimisation\"\"\"\n",
    "    Y = series[:,1:]\n",
    "    X = series[:,:-1]\n",
    "    V_cur = random_unit_matrix(series.shape[0],r).transpose()\n",
    "    for i in range(n_iter):\n",
    "        try :\n",
    "            U_cur = min_U(V_cur, X, Y)\n",
    "            V_cur = min_V(U_cur, X, Y)\n",
    "            if verbose:\n",
    "                print(empirical_risk(U_cur @ V_cur, series))\n",
    "        except:\n",
    "            return('Fail')\n",
    "    return U_cur @ V_cur\n",
    "\n",
    "def low_rank_estimator_by_projection(series, r= 10):\n",
    "    \"\"\"Low rank estimator approached using the projection of the standard estimator on the subset of low rank matrices\"\"\"\n",
    "    tot_estim = std_estimator(series)\n",
    "    U,D,V = np.linalg.svd(tot_estim)\n",
    "    D[r:] = 0\n",
    "    return U @ np.diag(D) @ V\n",
    "\n",
    "def low_rank_estimator_thrd(series, r= 10):\n",
    "    Y = series[:,1:]\n",
    "    X = series[:,:-1]\n",
    "    U,D,V = np.linalg.svd(Y,full_matrices=False)\n",
    "    D[r:] = 0\n",
    "    Yhat = U @ np.diag(D) @ V\n",
    "    return (Yhat @ X.transpose()) @  np.linalg.inv(X@ X.transpose() ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.C Penalized Full Rank Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "Another way to compare is to penalize the rank:\n",
    "\n",
    "$$  \\widehat{A}_{pen} = \\underset{A \\in \\mathcal{M}_{M \\times M }(\\mathbb{R})}{argmin} \\|Y- AX \\|_F^2  + C \\sqrt{rg(A)}$$\n",
    "\n",
    "This minimization is hard to compute in practice, beause we don't have an explicit formula for the low rank minimization. Furthermore it is impossible to use gradient-descent-like algorithm in this case because of the discontinuities.\n",
    "\n",
    "So we have to start from the problem for r:\n",
    "\n",
    "$$\\widehat{A_{lr}}(r) = \\underset{A \\in \\mathcal{M}_{M \\times M }(\\mathbb{R})\\\\ rg(A) = r }{argmin} \\|Y- AX \\|_F^2 $$ \n",
    "\n",
    "\n",
    "We are then trying to compute\n",
    "\n",
    "$$ \\widehat{r_{pen}} = \\underset{r \\in [0,M] }{argmin} \\|Y- \\widehat{A}_{lr}(r) X \\|_F^2  + C \\sqrt{r}$$\n",
    "\n",
    "and we use $\\widehat{A}_{lr}(r_{pen})$ as our objective matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def penalized_est(series, C = 1, return_rank = False, min_rank = 0 ):\n",
    "    \"\"\"Exact version of the penalized estimator using Early Stopping (take more time)\"\"\"\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    M = series.shape[0]\n",
    "    n = series.shape[1]\n",
    "    err = np.zeros(M-1)\n",
    "    list_mod = list()\n",
    "    curr_err = 0\n",
    "    old_err = float('inf')\n",
    "    for r in range(M-1):\n",
    "        \n",
    "        Ar_1 = low_rank_estimator(series, r=r+1)\n",
    "        curr_err = empirical_risk(Ar_1,series) + C* sqrt((r+1)* log(9*(r+1)))\n",
    "\n",
    "        if curr_err >= old_err or r==M-2:\n",
    "            r_min = r +1\n",
    "            break\n",
    "        Ar = Ar_1\n",
    "        old_err = curr_err\n",
    "    if return_rank:\n",
    "        return Ar, r_min\n",
    "    return Ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.D Nuclear norm regularisation\n",
    "\n",
    "Another possibility is to use the nuclear norm $\\| A \\|_1 $ to penalize the rank of the matrix [2]. We have then the following problem : \n",
    "\n",
    "$$  \\widehat{A}_{pen} = \\underset{A \\in \\mathcal{M}_{M \\times M }(\\mathbb{R})}{argmin} \\|Y- AX \\|_F^2  + C \\| A \\|_1$$\n",
    "\n",
    "We use the optimisation scheme described in [3].  Let's sketch the procedure noting $f(A) = \\|Y- AX \\|_F^2$. We define :\n",
    "\n",
    "$$ A_k = A_{k-1} - \\frac{1}{t_k}\\bigtriangledown f(A_{k-1}) $$ \n",
    "\n",
    "for a decreasing sequence $t_k$ of weight.The objective can be expressed as :\n",
    "\n",
    "\n",
    "$$ \\frac{t_k}{2}\\|A -\\left(A_{k-1} - \\frac{1}{t_k}\\bigtriangledown f(A_{k-1})\\right) \\|_F^2 + C \\|A\\|_1$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import svd\n",
    "from math import sqrt\n",
    "\n",
    "def gradf(A,X,Y):\n",
    "    return ( A @ X -Y ) @ np.transpose(X)\n",
    "\n",
    "\n",
    "def step_gradient_nuclear_norm(actual, X, Y, C, t):\n",
    "    new_mat = actual - 1/t * gradf(actual,X, Y)\n",
    "    try :\n",
    "        U, D, V = svd(new_mat)\n",
    "        lmbda = C /t\n",
    "        return U @ np.diag(np.maximum(0,D-lmbda)) @V\n",
    "    except:\n",
    "        return actual\n",
    "    \n",
    "\n",
    "def nuclear_norm_estimator(series,C =10 , n_iter=10, val = None):\n",
    "    Y = series[:,1:]\n",
    "    X = series[:,:-1]\n",
    "    M = X.shape[0]\n",
    "    \n",
    "    curr = np.random.rand(M,M)\n",
    "    for i in range(n_iter):\n",
    "        curr = step_gradient_nuclear_norm(curr, X,Y,C, (i+1)*50)\n",
    "        if not val is None:\n",
    "            print('Iteration : %s' %i)\n",
    "            print(np.linalg.norm(val[1] - curr @ val[0]))\n",
    "            print(np.linalg.norm(curr, 'nuc'))\n",
    "            print('======')\n",
    "    return curr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### II.E Slope Heuristics\n",
    "\n",
    "##### II.E.i Slope heuristics for penalized estimator\n",
    "\n",
    "We introduce the slope heuristics proposed by Birgé and Massart[1] to compute a good value for C. The idea is to compute the complexity of the best model $\\widehat{A_C}$ for each value of C.\n",
    "\n",
    "There is normaly a value $\\widehat{C}$ of C such that the complexity (here the rank of $\\widehat{A_C}$) is large if  $C < \\widehat{C}$ and reasonnable otherwise. The slope heuristics proposed to choose $\\tilde{C} = 2 * \\widehat{C} $ as the ideal value for the parameters $C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "A = generate_matrix(100,75,1)\n",
    "series = generate_series(A,1000)\n",
    "C_list = [0.02,0.05,0.1,0.2,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.4,1.5,2,5,10]\n",
    "r_obt  = list()\n",
    "for C in C_list:\n",
    "    Apen, r = penalized_est(series,C=C, return_rank = True)\n",
    "    r_obt.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "plt.style.use('bmh')\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(list(map(log, C_list)),r_obt)\n",
    "plt.xlabel('log(C)')\n",
    "plt.ylabel('rank')\n",
    "plt.title(\"Rank of $A_{pen}(C)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the slope change around C=1\n",
    "\n",
    "In order to find the point where the slope change, we compute the penalized estimator $\\widehat{A_{C_i}}$ for each coefficient $(C_i)_{i \\in [0,p]}$ . Then we compute the rank $r_{(C_i)}$ of each of these predictor.\n",
    "\n",
    "Then we choose:\n",
    "\n",
    "$$\\widehat{j} =  \\underset{i \\in [1,p-1]}{\\text{argmax}} (r_{C_{i+1}} - r_{C_{i}}) - (r_{C_{i}} - r_{C_{i-1}}) $$\n",
    "\n",
    "and we have $\\widehat{C} = C_{\\widehat{j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_C(C_list, series):\n",
    "    \"\"\"Find the ideal penalisation coefficient for the penalized estimator among C_list\"\"\"\n",
    "    r_obt  = list()\n",
    "    for C in C_list:\n",
    "        est = 'Fail'\n",
    "        while est == 'Fail':\n",
    "            est = penalized_est(series,C=C, return_rank = True)\n",
    "        Apen, r = est\n",
    "        if r == 1:\n",
    "            #Case where the ideal rank is 1\n",
    "            print(\"Low Rank\")\n",
    "            return 1\n",
    "        r_obt.append(r)\n",
    "    ser = pd.Series(r_obt)\n",
    "    j = np.argmax(ser.diff(1).diff(1).fillna(float('-inf')).values) - 2\n",
    "    if C_list[j] < 1:\n",
    "        return 2*C_list[j]\n",
    "    else:\n",
    "        return C_list[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_C(C_list,series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### II.E.ii Slope heuristic for Nuclear norm estimaor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "A = generate_matrix(100,75,1)\n",
    "series = generate_series(A,1000)\n",
    "C_nuc_list = [1,2,10,20,100,200, 1000,2000,10000,20000]\n",
    "r_obt  = list()\n",
    "for C in C_nuc_list:\n",
    "    Apen = nuclear_norm_estimator(series,C=C, n_iter = 100)\n",
    "    r = np.linalg.norm(Apen, 'nuc')\n",
    "    r_obt.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "plt.style.use('bmh')\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(list(map(log, C_nuc_list)),r_obt)\n",
    "plt.xlabel('log(C)')\n",
    "plt.ylabel('rank')\n",
    "plt.title(\"Rank of $A_{pen}(C)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_C_nuc(C_nuc_list, series):\n",
    "    \"\"\"Find the ideal penalisation coefficient for the penalized estimator among C_list\"\"\"\n",
    "    r_obt  = list()\n",
    "    for C in C_nuc_list:\n",
    "    \n",
    "        Apen = nuclear_norm_estimator(series,C=C, n_iter=100)\n",
    "        r = np.linalg.norm(Apen, 'nuc')\n",
    "        r_obt.append(r)\n",
    "    ser = pd.Series(r_obt)\n",
    "    j = np.argmax(ser.diff(1).diff(1).fillna(float('-inf')).values) - 2\n",
    "    if C_nuc_list[j] < 1:\n",
    "        return 2*C_nuc_list[j]\n",
    "    else:\n",
    "        return C_nuc_list[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience(M ,n,r,a , nb_iterations = 1000, nb_test= 100,C_list=np.geomspace(0.01,10,30)):\n",
    "    list_res = list()\n",
    "    \n",
    "    #Slope heuristics\n",
    "    A = generate_matrix(M,r,a)\n",
    "    series = generate_series(A, n + nb_test)\n",
    "    \n",
    "   \n",
    "    C=ideal_C(C_list, series)\n",
    "    lmd = ideal_C_nuc(C_list, series)\n",
    "    \n",
    "    for iteration in range(nb_iterations):\n",
    "        A = generate_matrix(M,r,a)\n",
    "        series = generate_series(A, n + nb_test)\n",
    "        train_set, test_set = series[:,:-nb_test], series[:,-nb_test:]\n",
    "        \n",
    "        A_std =  std_estimator(train_set)\n",
    "        A_low_rank = low_rank_estimator(train_set,r=r) \n",
    "        A_nuc = nuclear_norm_estimator(train_set,C=lmd,n_iter=100 ) \n",
    "        if A_low_rank != 'Fail':\n",
    "            A_pen = penalized_est(train_set, C=C, min_rank=0)\n",
    "            if A_pen != 'Fail':\n",
    "                min_risk =  empirical_risk(A, test_set)\n",
    "                err_1 = empirical_risk(A_std, test_set) - min_risk\n",
    "                err_2 = empirical_risk(A_low_rank, test_set) - min_risk\n",
    "                err_3 = empirical_risk(A_pen, test_set) - min_risk\n",
    "                err_4 = empirical_risk(A_nuc,test_set) -min_risk\n",
    "                list_res.append([err_1,err_2, err_3,err_4])\n",
    "    return np.array(list_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  III.A Rank Importance\n",
    "\n",
    "We fix the number n of observation, and we observe the risk excess for every estimator . We estimate the risk excess using 100 fresh values generated with A. There are some troubles with the matrix inversion, so there are some outliers. I suppose that this problem is caused by numerical problems while inversing quasi-non invertible matrics. I do not consider this matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "nb_iterations = 100 #Number of simulations for each point\n",
    "M = 100  #Numbers of series\n",
    "n_list = [200,500,1000,2000,5000] #length of series\n",
    "fontsize = 18\n",
    "reponses = []\n",
    "\n",
    "#We test the following rank\n",
    "ranks = [2,3,5,7,10,15,20,30,50,75,100]\n",
    "#ranks = [50,75,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CDBDX/remy.garnier/.virtualenvs/python_3.6_TS/lib/python3.6/site-packages/ipykernel_launcher.py:22: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/CDBDX/remy.garnier/.virtualenvs/python_3.6_TS/lib/python3.6/site-packages/ipykernel_launcher.py:24: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 3 \n",
      "Rank: 5 \n",
      "Rank: 7 \n",
      "Rank: 10 \n",
      "Rank: 15 \n",
      "Rank: 20 \n",
      "Rank: 30 \n",
      "Rank: 50 \n",
      "Rank: 75 \n",
      "Rank: 100 \n",
      "Rank: 2 \n",
      "Rank: 3 \n",
      "Rank: 5 \n",
      "Rank: 7 \n",
      "Rank: 10 \n",
      "Rank: 15 \n",
      "Rank: 20 \n",
      "Rank: 30 \n",
      "Rank: 50 \n",
      "Rank: 75 \n",
      "Rank: 100 \n",
      "Rank: 2 \n",
      "Rank: 3 \n",
      "Rank: 5 \n",
      "Rank: 7 \n",
      "Rank: 10 \n",
      "Rank: 15 \n",
      "Rank: 20 \n",
      "Rank: 30 \n",
      "Rank: 50 \n",
      "Rank: 75 \n",
      "Rank: 100 \n",
      "Rank: 2 \n",
      "Rank: 3 \n",
      "Rank: 5 \n",
      "Rank: 7 \n",
      "Rank: 10 \n",
      "Rank: 15 \n",
      "Rank: 20 \n",
      "Rank: 30 \n",
      "Rank: 50 \n",
      "Rank: 75 \n",
      "Rank: 100 \n",
      "Rank: 2 \n",
      "Rank: 3 \n",
      "Rank: 5 \n",
      "Rank: 7 \n",
      "Rank: 10 \n",
      "Rank: 15 \n",
      "Rank: 20 \n",
      "Rank: 30 \n",
      "Rank: 50 \n",
      "Rank: 75 \n",
      "Rank: 100 \n",
      "Rank: 2 \n",
      "Rank: 3 \n",
      "Rank: 5 \n",
      "Rank: 7 \n",
      "Rank: 10 \n",
      "Rank: 15 \n",
      "Rank: 20 \n",
      "Rank: 30 \n",
      "Rank: 50 \n",
      "Rank: 75 \n",
      "Rank: 100 \n",
      "Rank: 2 \n",
      "Rank: 3 \n",
      "Rank: 5 \n",
      "Rank: 7 \n",
      "Rank: 10 \n",
      "Rank: 15 \n",
      "Rank: 20 \n",
      "Rank: 30 \n",
      "Rank: 50 \n",
      "Rank: 75 \n",
      "Rank: 100 \n",
      "Rank: 2 \n",
      "Rank: 3 \n",
      "Rank: 5 \n",
      "Rank: 7 \n",
      "Rank: 10 \n",
      "Rank: 15 \n",
      "Rank: 20 \n",
      "Rank: 30 \n",
      "Rank: 50 \n",
      "Rank: 75 \n",
      "Rank: 100 \n",
      "Rank: 2 \n",
      "Rank: 3 \n",
      "Rank: 5 \n",
      "Rank: 7 \n",
      "Rank: 10 \n",
      "Rank: 15 \n",
      "Rank: 20 \n",
      "Rank: 30 \n",
      "Rank: 50 \n",
      "Rank: 75 \n",
      "Rank: 100 \n",
      "Rank: 2 \n",
      "Rank: 3 \n",
      "Rank: 5 \n",
      "Rank: 7 \n",
      "Rank: 10 \n",
      "Rank: 15 \n",
      "Rank: 20 \n",
      "Rank: 30 \n",
      "Rank: 50 \n",
      "Rank: 75 \n",
      "Rank: 100 \n"
     ]
    }
   ],
   "source": [
    "for n in n_list:\n",
    "    list_alpha = [0.5,1]\n",
    "    list_rep = list()\n",
    "    for alpha in list_alpha:\n",
    "        list_inter = list()\n",
    "        for rank in ranks:\n",
    "            print('Rank: %s ' %rank)\n",
    "            list_inter.append(experience(M, n, rank,alpha,nb_iterations=nb_iterations))\n",
    "        list_rep.append(list_inter)\n",
    "    reponses.append(list_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_n =2\n",
    "i_alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_list =list()\n",
    "type_list = ['full rank', 'oracle','penalized','nuclear']\n",
    "for rank in ranks:\n",
    "    ab_list += [rank]*(4*nb_iterations)\n",
    "\n",
    "dat = np.concatenate(reponses[i_n][i_alpha],axis = 0)\n",
    "df_l = pd.DataFrame(dat)\n",
    "df_l.columns = type_list\n",
    "df_l = df_l.stack()\n",
    "df_l = df_l.reset_index()\n",
    "df_l.drop(columns  ='level_0', inplace= True)\n",
    "df_l['rank'] = ab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.style.use('bmh')\n",
    "ax = sns.boxplot(data=df_l,hue = 'level_1', x='rank',y= 0, palette='Greys')\n",
    "#ax.set_title('Excess quadratic risk for lambda = ' +str(title[0]) +' and n = ' + str(n), fontsize = fontsize)\n",
    "ax.set_xlabel('Rank', fontsize = fontsize)\n",
    "ax.set_ylabel('Excess quadratic risk', fontsize = fontsize)\n",
    "ax.legend(fontsize =fontsize-4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l.to_csv('Save_n='+ str(n_list[i_n]) +'_M=' + str(M) + '_' + str(list_alpha[i_alpha]) + '_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ayy = df_l.groupby(['level_1','rank']).mean().unstack().to_latex(float_format=\"%.2f\")\n",
    "print(ayy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the perfomance of the full rank regression doesn't seem to be affected by the rank of the underlying matrices. Low rank regression perfoms faster than the other regression and better when the underlying rank of matrix are small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Birg\u0013e, L. and Massart, P. (2006). Minimal penalties for gaussian model selection.\n",
    "Probability Theory and Related Fields, 138(1-2):33{73.\n",
    "\n",
    "[2]  Negahban, Sahand and Wainwright, Martin J. (2011) Estimation of (near) low-rank matrices with noise and high-dimensional scaling. The Annals of Statistics\n",
    "\n",
    "[3] Ji, Shuiwang & Ye, Jieping. (2009). An accelerated gradient method for trace norm minimization. Proceedings of the 26th International Conference On Machine Learning, ICML 2009. 58. 10.1145/1553374.1553434. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
